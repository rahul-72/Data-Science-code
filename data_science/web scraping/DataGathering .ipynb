{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data wrangling process:\n",
    "\n",
    "* Gather (this lesson)\n",
    "* Assess\n",
    "* Clean\n",
    "\n",
    "Gathering data is the first step in data wrangling. Before gathering, we have no data, and after it, we do.\n",
    "\n",
    "Gathering data varies from project to project. Sometimes you're just given data, or pointed to it like I've done for you throughout this course. Sometimes you need to search for the right data for your project. Sometimes the data you need isn't readily available, and you need to generate it yourself somehow. When you do find your data, it's not unusual for it to be spread across several different sources and file formats, which makes things tricky when organizing the data in your programming environment.\n",
    "\n",
    "For these reasons and more, gathering can be tricky. In this lesson, which is likely the most technically challenging lesson of the course, you'll acquire the coding skills and general craftiness required to conquer the vast majority of gathering scenarios you'll come across in the future. This is going to be hard sometimes, and that's okay. Stick with it and don't hesitate to reach out for help.\n",
    "\n",
    "### This lesson will be structured as follows:\n",
    "\n",
    "* First, we'll pose a few questions.\n",
    "* Then you'll explore the source of each piece of data we need to answer those questions, each piece from a different source and in a different format.\n",
    "* Then you'll learn about the structure of each file format.\n",
    "* Then you'll learn how to handle that file format using Python and its libraries.\n",
    "* Then you'll actually gather each piece of data to later join together to create your master dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Site to Scrap data From\n",
    "\n",
    "\n",
    "https://www.rottentomatoes.com/top/bestofrt/\n",
    "    \n",
    "https://www.rogerebert.com/\n",
    "    \n",
    "https://amueller.github.io/word_cloud/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating Your Working Directory and File I/O\n",
    "\n",
    "Before you continue on with this lesson, make sure you are comfortable working with your computer's command line interface to access files and folders, and also with reading and writing to files (i.e. part of File I/O or input/output) in Python. It can be extremely frustrating getting bogged down in these seemingly trivial topics.\n",
    "\n",
    "### Command Line\n",
    "\n",
    "For the command line interface, here are three excellent resources that I recommend. Pick whichever suits you best:\n",
    "\n",
    "* Navigating the Terminal: A Gentle Introduction by Marius Masalar (for Mac users) https://computers.tutsplus.com/tutorials/navigating-the-terminal-a-gentle-introduction--mac-3855\n",
    "\n",
    "* Command Prompt - How to use the simple, basic commands by Codrut Neagu (for Windows users) https://www.digitalcitizen.life/command-prompt-how-use-basic-commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotten Tomatoes Top 100 Movies of All Time TSV File \n",
    "\n",
    "Note: Internal data from a database can be downloaded programmatically from the file storage systems (like Google Drive) for some companies, though it is often trickier than downloading a file hosted on a web page. In practice, internal files aren't often downloaded programmatically for wrangling and analysis/visualization/modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Files \n",
    "\n",
    "Flat files contain tabular data in plain text format with one data record per line and each record or line having one or more fields. These fields are separated by delimiters, like commas, tabs, or colons.\n",
    "\n",
    "#### Advantages of flat files include:\n",
    "\n",
    "* They're text files and therefore human readable.\n",
    "* Lightweight.\n",
    "* Simple to understand.\n",
    "* Software that can read/write text files is ubiquitous, like text editors.\n",
    "* Great for small datasets.\n",
    "\n",
    "\n",
    "#### Disadvantages of flat files, in comparison to relational databases, for example, include:\n",
    "\n",
    "* Lack of standards.\n",
    "* Data redundancy.\n",
    "* Sharing data can be cumbersome.\n",
    "* Not great for large datasets (see \"When does small become large?\" in the Cornell link in More Information).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Quiz\n",
    "\n",
    "Are the files pictured below flat files? Match yes or no to each file number in the following quiz.\n",
    "\n",
    "\n",
    "###  File #1: animals.csv\n",
    "\n",
    "<img src=\"file1.png\" height=400 width=400>\n",
    "\n",
    "### File #2: animals.tsv\n",
    "\n",
    "<img src=\"file2.png\" height=400 width=400>\n",
    "\n",
    "### File #3: animals.txt\n",
    "\n",
    "<img src=\"file3.png\" height=400 width=400>\n",
    "\n",
    "### File #4: animals.txt\n",
    "\n",
    "<img src=\"file4.png\" height=400 width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUIZ QUESTION\n",
    "\n",
    "#### Are the files pictured above flat files?\n",
    "\n",
    "##### Values \n",
    "    \n",
    "    Yes, No \n",
    "    \n",
    "#### Files \n",
    "\n",
    "    #1. animals.csv\n",
    "    #2. animals.tsv\n",
    "    #3. animals.txt\n",
    "    #4. animals.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources \n",
    "\n",
    "\n",
    "* Professor Excel:XML & ZIP:<a href=\"https://professor-excel.com/xml-zip-excel-file-structure/\"> Explore Your Excel Workbooks File Structures </a>\n",
    "\n",
    "* Cornell: Relational Databases -<a href=\"https://www.cac.cornell.edu/education/Training/DataAnalysis/RelationalDatabases.pdf\"> Not Your Father's Flat Files</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files in Python\n",
    "\n",
    "pandas has one main function for parsing flat files and it is read_csv. Here is a link to its <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\">documentation.</a>\n",
    "\n",
    "<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/index.html\">Flat Files in Pandas </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"bestofrt.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>title</th>\n",
       "      <th>number_of_critic_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>The Wizard of Oz (1939)</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>Get Out (2017)</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>Mad Max: Fury Road (2015)</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  critic_score                      title  number_of_critic_ratings\n",
       "0        1            99    The Wizard of Oz (1939)                       110\n",
       "1        2           100        Citizen Kane (1941)                        75\n",
       "2        3           100       The Third Man (1949)                        77\n",
       "3        4            99             Get Out (2017)                       282\n",
       "4        5            97  Mad Max: Fury Road (2015)                       370"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEB Scraping\n",
    "* <a href=\"https://www.rottentomatoes.com/m/et_the_extraterrestrial\">Rotten Tomatoes: E.T. the Extra-Terrestrial (1982)</a>\n",
    "* <a href=\"https://www.crummy.com/software/BeautifulSoup/\">Beautiful Soup</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving HTML\n",
    "\n",
    "The two main ways to work with HTML files are:\n",
    "\n",
    "* Saving the HTML file to your computer (using the <a href=\"https://2.python-requests.org//en/master/\">Requests library</a> for example) library and reading that file into a<b> BeautifulSoup constructor</b>\n",
    "* Reading the HTML response content directly into a BeautifulSoup constructor (again using the Requests library for example)\n",
    "\n",
    "You'll learn how this Requests code works under the hood shortly in “Downloading Files from The Internet.”\n",
    "\n",
    "<p>For this lesson, you’re going to do neither of these. I've downloaded all of the Rotten Tomatoes HTML files for you and put them in a folder called rt_html. I recommend that you do and open the HTML files in your preferred text editor (e.g.<a href=\"https://www.sublimetext.com/\"> Sublime</a>, which is free) to inspect the HTML for the quizzes ahead.</p>\n",
    "\n",
    "The rt_html folder contains the Rotten Tomatoes HTML for each of the Top 100 Movies of All Time as the list stood at the most recent update of this lesson. I'm giving you these historical files because the ratings will change over time and there will be inconsistencies with the recorded lesson videos. Also, a web page's HTML is known to change over time. Scraping code can break easily when web redesigns occur, which makes scraping brittle and not recommended for projects with longevity. So just use these HTML files provided to you and pretend like you saved them yourself with one of the methods described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Information\n",
    "\n",
    "* <a href=\"https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01\"> Towards Data Science: Ethics in Web Scraping</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML File Structure\n",
    "\n",
    "Quiz\n",
    "\n",
    "With your knowledge of HTML file structure, you're going to use Beautiful Soup to extract our desired Audience Score metric and number of audience ratings, along with the movie title like in the video above (so we have something to merge the datasets on later) for each HTML file, then save them in a pandas DataFrame.\n",
    "\n",
    "The Jupyter Notebook below contains template code that:\n",
    "\n",
    "Creates an empty list, df_list, to which dictionaries will be appended. This list of dictionaries will eventually be converted to a pandas DataFrame (this is the most efficient way of building a DataFrame row by row).\n",
    "Loops through each movie's Rotten Tomatoes HTML file in the rt_html folder.\n",
    "Opens each HTML file and passes it into a file handle called file.\n",
    "Creates a DataFrame called df by converting df_list using the pd.DataFrame constructor.\n",
    "Your task is to extract the title, audience score, and number of audience ratings in each HTML file so each trio can be appended as a dictionary to df_list.\n",
    "\n",
    "The Beautiful Soup methods required for this task are:\n",
    "\n",
    "find()\n",
    "find_all()\n",
    "There is an excellent tutorial on these methods (Searching the tree) in the Beautiful Soup documentation. Please consult that tutorial if you are stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree\n",
    "  \n",
    "https://stackoverflow.com/questions/28056171/how-to-build-and-fill-pandas-dataframe-from-for-loop/28058264#28058264\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
